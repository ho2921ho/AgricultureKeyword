{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b4663f6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keybert\n",
      "  Downloading keybert-0.7.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting sentence-transformers>=0.3.8\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ---------------------------------------- 86.0/86.0 kB 5.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from keybert) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from keybert) (1.21.5)\n",
      "Collecting rich>=10.4.0\n",
      "  Downloading rich-13.3.1-py3-none-any.whl (239 kB)\n",
      "     -------------------------------------- 239.0/239.0 kB 7.4 MB/s eta 0:00:00\n",
      "Collecting pygments<3.0.0,>=2.14.0\n",
      "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 7.9 MB/s eta 0:00:00\n",
      "Collecting markdown-it-py<3.0.0,>=2.1.0\n",
      "  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n",
      "     ---------------------------------------- 84.5/84.5 kB 5.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22.2->keybert) (1.9.1)\n",
      "Collecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 8.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\nh\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (4.64.1)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.13.1-cp39-cp39-win_amd64.whl (162.5 MB)\n",
      "     -------------------------------------- 162.5/162.5 MB 7.4 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.14.1-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 8.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk in c:\\users\\nh\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.3.8->keybert) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 8.0 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
      "     ------------------------------------- 190.3/190.3 kB 12.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\nh\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\nh\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (4.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (21.3)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\nh\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers>=0.3.8->keybert) (0.4.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.3.8->keybert) (2022.7.9)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-win_amd64.whl (3.3 MB)\n",
      "     ---------------------------------------- 3.3/3.3 MB 9.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\nh\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers>=0.3.8->keybert) (8.0.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers>=0.3.8->keybert) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nh\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.3.8->keybert) (2022.9.14)\n",
      "Building wheels for collected packages: keybert, sentence-transformers\n",
      "  Building wheel for keybert (setup.py): started\n",
      "  Building wheel for keybert (setup.py): finished with status 'done'\n",
      "  Created wheel for keybert: filename=keybert-0.7.0-py3-none-any.whl size=23776 sha256=ba48959139039f4d87723c7d9d85e876af9d498497e533fecda6b9beb0cb8600\n",
      "  Stored in directory: c:\\users\\nh\\appdata\\local\\pip\\cache\\wheels\\68\\aa\\41\\82025d89b0eb97484c9ac7d527abf596765c41733af79f86b0\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=7d1de36a1615380ac942a348aa9cf722ec625992136f60b2493d1f457d906b9f\n",
      "  Stored in directory: c:\\users\\nh\\appdata\\local\\pip\\cache\\wheels\\71\\67\\06\\162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built keybert sentence-transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, torch, pygments, mdurl, torchvision, markdown-it-py, huggingface-hub, transformers, rich, sentence-transformers, keybert\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "Successfully installed huggingface-hub-0.12.0 keybert-0.7.0 markdown-it-py-2.1.0 mdurl-0.1.2 pygments-2.14.0 rich-13.3.1 sentence-transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 torch-1.13.1 torchvision-0.14.1 transformers-4.26.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 5.2.2 requires pyqt5<5.13, which is not installed.\n",
      "spyder 5.2.2 requires pyqtwebengine<5.13, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "!pip3 install keybert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1de4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keybert import KeyBERT\n",
    "import pickle\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30ca1a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc2key(cleaned_content):\n",
    "    \n",
    "    kw_model = KeyBERT(model='all-MiniLM-L6-v2')\n",
    "    keywords = kw_model.extract_keywords(doc)\n",
    "    \n",
    "    n2_kwd = kw_model.extract_keywords(cleaned_content, keyphrase_ngram_range=(2, 2), stop_words='english',\n",
    "                                  use_mmr=True, diversity=0.7, top_n=5)\n",
    "\n",
    "    n1_kwd = kw_model.extract_keywords(cleaned_content, keyphrase_ngram_range=(1, 1), stop_words='english',\n",
    "                                  use_mmr=True, diversity=0.7, top_n=10)\n",
    "    for idx,i in enumerate(n2_kwd):\n",
    "        n2_kwd[idx] = i[0]\n",
    "    for idx,i in enumerate(n1_kwd):\n",
    "        n1_kwd[idx] = i[0]  \n",
    "\n",
    "    n1_kwd.extend(n2_kwd)\n",
    "    kwd = n1_kwd\n",
    "    return kwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c831a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from_date = '2023-1-30'\n",
    "to_date = '2023-1-31'\n",
    "searching_word = 'metaverse'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dca06d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"News{}-{}.pickle\".format(from_date,to_date)\n",
    "name = name.replace('/','.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9963b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae9482d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_path = cwd + '/' + searching_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7eb3cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(main_path + '/' + 'news/' + name, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c73bdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dae53de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.rename({\"index\":\"date\"},axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7f4af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = []\n",
    "for x in data['date']:\n",
    "    tmp = x.split('/')\n",
    "    if len(tmp[0]) == 1:\n",
    "        tmp[0] = '0'+tmp[0]\n",
    "    if len(tmp[1]) == 1:\n",
    "        tmp[1] = '0'+tmp[1]\n",
    "    tmp = tmp[2] + tmp[0] + tmp[1]\n",
    "    idx.append(''.join(tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "274aa345",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = idx\n",
    "data = data.rename({'date':'일자'},axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e770435d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:29<00:00, 14.63s/it]\n"
     ]
    }
   ],
   "source": [
    "kwd_list = []\n",
    "for docs in tqdm(data['news']):\n",
    "    kwds = []\n",
    "    for doc in docs:\n",
    "        try:\n",
    "            cleaned_content = re.sub(r'[^\\.\\?\\!\\w\\d\\s]','',doc) # 문장단위로 끊기\n",
    "            cleaned_content = cleaned_content.replace('\\n',' ')\n",
    "            cleaned_content = cleaned_content.lower()\n",
    "            kwd = doc2key(cleaned_content)\n",
    "            kwds.append(kwd)\n",
    "        except:\n",
    "            print(doc)\n",
    "    kwd_list.append(kwds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "339ebd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['kwd'] = kwd_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbc57714",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Keyword{}-{}.pickle\".format(from_date,to_date)\n",
    "name = name.replace('/','.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2e9c433e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(main_path + '/' + 'keyword/' + name,'wb') as f:\n",
    "    pickle.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "145819b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokens',\n",
       " 'floki',\n",
       " 'trillion',\n",
       " 'bridge',\n",
       " 'calamitous',\n",
       " 'stability',\n",
       " 'relocation',\n",
       " 'disclaimer',\n",
       " 'rationale',\n",
       " 'launching',\n",
       " 'burning tokens',\n",
       " 'floki primary',\n",
       " 'risks bridges',\n",
       " 'disappeared crosschain',\n",
       " 'pricing ratio']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['kwd'][0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
